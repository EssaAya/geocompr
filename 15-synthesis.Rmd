# Conclusion {#conclusion}

## Prerequisites {-}

Like the introduction, this concluding chapter contains few code chunks.
But its prerequisites are demanding.
It assumes that you have:

- read-through and attempted the exercises in all the chapters of Part 1 (Foundations)
- grasped the diversity of methods that build on these foundations, by following the code and prose in Part 2 (Extensions)
- considered how you can use geocomputation to solve real-world problems, at work and beyond, after engaging with Part 3 (Applications).

The aim is to consolidate knowledge and skills for geocomputation and inspire future directions of application and development.
<!-- Section \@ref(concepts) reviews the content covered in the previous chapters but at a high level. -->
<!-- Previous chapters focus on the details of packages, functions and arguments needed for geocomputation with R. -->
<!-- This chapter focuses on concepts that recur throughout the book and how they may be useful. -->
Section \@ref(gaps) discusses gaps in the book's contents and explains why some areas of research were deliberately omitted while others were included multiple times.
This discussion forms the foundation for section \@ref(next), which asks:
having read this book, where to next?

<!-- Section \@ref(next) -->

<!-- Section \@ref(benefit) -->

<!-- ## Concepts for geocomputation {#concepts} -->

## Gaps and overlaps {#gaps}

A characteristic of R is that there are often multiple ways to acheive the same result.
Geocomputation with R is no exception.
The code chunk below illustrates this by using 3 functions
<!-- from 3 packages (**sf**, base R's **stats** and tidyverse's **dplyr**) -->
based on **sf**
to generate the same result, a single feature representing New Zealand from its 16 regions:

```{r}
library(spData)
nz_u1 = sf::st_union(nz)
nz_u2 = aggregate(nz["Population"], list(rep(1, nrow(nz))), sum)
nz_u3 = dplyr::summarise(nz, t = sum(Population))
identical(nz_u1, nz_u2$geometry)
identical(nz_u1, nz_u3$geom)
```

Although the results of the three operations differ, the underlying geometry they create is the same, as verified using the base R function `identical()`.^[
The first operation, undertaken by the function `st_union()`, creates an object of class `sfc` (a simple feature column).
The latter two operations create `sf` objects, each of which *contains* a simple feature column.
Therefore it is the geometries contained in simple feature columns, not the objects themselves, that are identical.
]
Which to use?
It depends: the latter two options performed attribute operations, which may be useful for your work.
Choosing between base R and the tidyverse is largely a matter of preference.

Another area of overlap is *between* packages.
Chapter \@ref(intro) mentions 20+ influential spatial packages that have been developed over the years.
Although each package covered in this book has a different emphasis, there is inevitably overlap between them, and there are dozens more packages for geographic data:
There are 176 packages in the Spatial [Task View](https://cran.r-project.org/web/views/) alone (as of summer 2018), and more packages and countless functions for geographic data are developed each year.

The volume and development velocity of geographic functions makes it practically impossible to keep-up with all of the developments in the broadly defined 'R-spatial' community (section \@ref(next) covers developments in other languages).
There is much overlap and some packages perform much better than others, making package selection an important decision.
From this diversity we have chosen packages that we believe are worth learning because they are future-proof (i.e. they will be maintained into the future), high performance (relative to other R packages) and complimentary.
But there is still much overlap between them, as illustrated by the diversity of packages in the field of geographic data visualization alone (see Chapter \@ref(adv-map)).
Overlaps between packages are not a bad thing: they ensure the resilience of the wider R ecosystem and provide choice.
Choice is a key feature of open source software.
When using a particular 'stack', such as the **sf**/**tidyverse**/**raster** ecosystem advocated in this book, it is worth being aware of alternatives already developed (such as **sp**/**rgdal**/**rgeos**) and under development.

```{r, eval=FALSE, echo=FALSE}
# aim: find number of packages in the spatial task view
# how? see:
# vignette("selectorgadget")
stv_pkgs = xml2::read_html("https://cran.r-project.org/web/views/Spatial.html")
pkgs = html_nodes(stv_pkgs, "ul:nth-child(5) a")
pkgs_char = html_text(pkgs)
length(pkgs_char)
```

Likewise, there are gaps and overlaps in the contents of this book, which are worth considering before we consider next steps in the next section.

<!-- More than 15 years ago, before most of the packages used in this book had been developed,  -->

## Where next? {#next}

Learning geocomputation with R is challenging and there is much more to discover.
We have progressed quickly.
The jump from chapters \@ref(spatial-class) to \@ref(eco) is large:
the creation and manipulation of simple spatial objects Part I may seem a world away from the analysis of large datasets covered in Part III.
It is impossible to become an expert in any area by reading a single book, and skills must be practiced.
This section points toward sensible next steps on your geocomputational journey, **highlighted in bold below**.
<!-- and ordered by difficulty, beginning with continue to improve your knowledge of R. -->

The language of R is a shared thread connecting all the chapters.
All the analyses are based on R classes, primarily `sf` and `raster`, which in turn build on the base R classes of `data.frame` and `matrix`.
The wider point is the importance of *depth of understanding*.
This observation suggests a direction of travel: **improving your understanding of the R language**.
A next step in this direction is to deepen your knowledge of base R, for example by: studying R's key documents (which can be found by entering `help.start()` in the console), reading and playing with the source code of useful functions, or reading comprehensive resources on the subject such those by @wickham_advanced_2014 and @chambers_extending_2016.
<!-- creating and querying simple spatial in Chapter \ref(spatial-class) -->

<!-- Many directions of travel could be taken after taking the geocomputational steps -->
Perhaps the most obvious direction of future learning is **discovering geocomputation with other languages**.
There are good reasons for learning R as a language for geocomputation, as described in Chapter \@ref(intro), but it is not the only option.^[
R's strengths relevant to our definition geocomputation in,clude its emphasis on scientific reproducibility, widespread use in academic research and unparalleled support for statistical modelling of geographic data.
Furthermore we advocate learning one language (R) for geocomputation in depth before delving into other languages/frameworks because of the costs associated with context switching.
It is preferable to have expertise in one language than basic knowledge of many.
]
It is possible to study *Geocomputation with Python*, *C++*, *JavaScript*, *Scala*, *Julia* or *Rust* in equal depth.
Each of these is a promising language for geocomputation.
[**Turf.js**](https://github.com/Turfjs/turf), for example, provides many functions for geospatial analysis with implementations in JavaScript, Julia and even Swift.
[**rasterio**](https://github.com/mapbox/rasterio) is a Python package for raster offering a high-performance interface to GDAL for handling raster data.
These and other tantalizing geospatial software projects can be found on the GitHub repo [Awesome-Geospatial](https://github.com/sacridini/Awesome-Geospatial).

## Geocomputation for social benefit {#benefit}

This is a technical book so it makes sense for the next steps to be of a technical nature.
However, as we saw in section \@ref(what-is-geocomputation), geocomputation originated as a field that has three main ingredients:

- the *creative* use of geographic data
- application to *real world problems* for social benefit
- building new tools

We emphasize the first two ingredients because these broader non-technical aims make geospatial analysis so rewarding:
what is the point of building new new geographic method (tool) if its only purpose is to increase sales of perfume?
<!-- None. -->

Building on the three key components of geocomputation mentioned above and described in early work [@openshaw_geocomputation_2000], we added another: reproducibility.
Reproducibility is a worthwhile aim in itself but it also supports *creativity* and the application of geographic methods to *real world problems*.
Reproducibility encourages the focus of methods to shift away from the basics
<!-- (which are readility available through shared code) -->
and toward unusual applications.
<!-- that nobody has yet thought of. -->
Reproducibility encourages geocomputation for social benefit because it makes geographic data analysis publicly accessible and transparent.

Think of the person using geocomputation to increase sales of perfume.
They have developed a powerful new method combining multiple geographic data sources.
If only people in the company have access to the underlying code, few people benefit.
If they make their code open and reproducible, by contrast, the methods can be re-used for socially beneficial purposes.
Furthermore, if they contribute upstream to packages they have used for their work, everyone benefits.
One accessible way to contribute upstream is creating a reprex (reproducible example) to highlight a bug in the package's issue tracker, as outlined in section \@ref(scripts). 

<!-- Like any worthwhile intellectual endeavour or nascent academic field geocomputation is diverse and contested. -->
<!-- An editorial celebrating '21+ years of geocomputation' reflects on two decades of research that falls under the geocomputational banner [@harris_more_2017]. -->
